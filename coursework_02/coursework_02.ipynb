{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XRxHiKdGHiT"
      },
      "source": [
        "# Coursework 2: Image segmentation\n",
        "\n",
        "In this coursework you will develop and train a convolutional neural network for brain tumour segmentation. Please read both the text and the code in this notebook to get an idea what you are expected to implement. Pay attention to the missing code blocks that look like this:\n",
        "\n",
        "```\n",
        "### Insert your code ###\n",
        "...\n",
        "### End of your code ###\n",
        "```\n",
        "## What is expected?\n",
        "\n",
        "* Complete and run the code using `jupyter-lab`.\n",
        "\n",
        "* Export (File | Save and Export Notebook As...) the notebook as a PDF file, which contains your code, results and answers, and upload the PDF file onto [Scientia](https://scientia.doc.ic.ac.uk).\n",
        "\n",
        "* If Jupyter complains issues during exporting, it is likely that [pandoc](https://pandoc.org/installing.html) or latex is not installed, or their paths have not been included. You can install the relevant libraries and retry. Alternatively, use the Print function of your browser to export the PDF file.\n",
        "\n",
        "* If Jupyter-lab does not work for you at the end, alternatively, you can use Google Colab to write the code and export the PDF file.\n",
        "\n",
        "## Dependencies\n",
        "\n",
        "You need to install Jupyter-Lab (https://jupyterlab.readthedocs.io/en/stable/getting_started/installation.html) and other libraries used in this coursework, such as by running the command:\n",
        "`pip3 install [package_name]`\n",
        "\n",
        "## GPU resource\n",
        "\n",
        "The coursework is developed to be able to run on CPU, as all images have been pre-processed to be 2D and of a smaller size, compared to original 3D volumes.\n",
        "\n",
        "However, to save training time, you may want to use GPU. In that case, you can run this notebook on Google Colab. On Google Colab, go to the menu, Runtime - Change runtime type, and select **GPU** as the hardware acceleartor. At the end, please still export everything and submit as a PDF file on Scientia.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Eq1KWmR3HWYV"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "# These libraries should be sufficient for this tutorial.\n",
        "# However, if any other library is needed, please install by yourself.\n",
        "import tarfile\n",
        "import imageio\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4TX-CXBHW4c"
      },
      "source": [
        "## Q1. Download and visualise the imaging dataset.\n",
        "\n",
        "The dataset is a public brain imaging dataset from [Medical Decathlon Challenge](http://medicaldecathlon.com/). To save the storage and reduce the computational cost for this tutorial, we extract 2D image slices from the original 3D volumes (T1-Gd contrast enhanced imaging) and downsample the 2D images.\n",
        "\n",
        "The dataset consists of a training set and a test set. Each image is of dimension 120 x 120, with a corresponding label map of the same dimension. There are four number of classes in the label map:\n",
        "\n",
        "- 0: background\n",
        "- 1: edema\n",
        "- 2: non-enhancing tumour\n",
        "- 3: enhancing tumour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mt93oQ8xZkE9",
        "outputId": "06a14eb5-46c5-4ee4-a80c-a672109916d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-08 20:32:46--  https://www.dropbox.com/s/zmytk2yu284af6t/Task01_BrainTumour_2D.tar.gz\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.69.18, 2620:100:6031:18::a27d:5112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.69.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.dropbox.com/scl/fi/4bf8fqcfgf3lebiv2in99/Task01_BrainTumour_2D.tar.gz?rlkey=ceq898g2tr3aaxjxn4xjxbob1 [following]\n",
            "--2026-02-08 20:32:47--  https://www.dropbox.com/scl/fi/4bf8fqcfgf3lebiv2in99/Task01_BrainTumour_2D.tar.gz?rlkey=ceq898g2tr3aaxjxn4xjxbob1\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc0798418d55059d281dff55852a.dl.dropboxusercontent.com/cd/0/inline/C6jEbl3ybwU5-MnuASS9GifdVFqcL_BoKeoilObHsm4yMmYVmobFUxanq-I_vQqv_5L9jA0D4RZQJ3QEocXIULAW3Tc1wXw0bLqQmu2tKkEuJgTBkMD2mmhhE9Ik_iPWjvw/file# [following]\n",
            "--2026-02-08 20:32:48--  https://uc0798418d55059d281dff55852a.dl.dropboxusercontent.com/cd/0/inline/C6jEbl3ybwU5-MnuASS9GifdVFqcL_BoKeoilObHsm4yMmYVmobFUxanq-I_vQqv_5L9jA0D4RZQJ3QEocXIULAW3Tc1wXw0bLqQmu2tKkEuJgTBkMD2mmhhE9Ik_iPWjvw/file\n",
            "Resolving uc0798418d55059d281dff55852a.dl.dropboxusercontent.com (uc0798418d55059d281dff55852a.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6030:15::a27d:500f\n",
            "Connecting to uc0798418d55059d281dff55852a.dl.dropboxusercontent.com (uc0798418d55059d281dff55852a.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/C6i2gzSO0Fm8FCc1vyrI68km6uZao4z_Gp7qyVF69jeXmpqvBRrnIOrntuOI63-WBoAK81yCsHq-Hs9_9hKoynu3gdgnA_3QZGvLOXhXz8Px5uhHa0n1BmG9PfRj9MnKJLqN4263569ygHsFl-aX04i-l7SnNWthSdl0w_-QXsUlgpqyFG4Gswaewo7pSHjf2jBU07NyPEk3eyQ9foVrznwGSO3LHdvGyqyGQ-z_X2meVuGlONc1udQuz4mWaeiMNLea_7-EolzegKGKH-jakAFgmX4sqjPkVoB2SiCm3lytFyYe6kj1rb-WSrsOxM184ZI6o4k9KCoJW5croBK12WiGz7csyWn3CxItkZM7adHMsw/file [following]\n",
            "--2026-02-08 20:32:49--  https://uc0798418d55059d281dff55852a.dl.dropboxusercontent.com/cd/0/inline2/C6i2gzSO0Fm8FCc1vyrI68km6uZao4z_Gp7qyVF69jeXmpqvBRrnIOrntuOI63-WBoAK81yCsHq-Hs9_9hKoynu3gdgnA_3QZGvLOXhXz8Px5uhHa0n1BmG9PfRj9MnKJLqN4263569ygHsFl-aX04i-l7SnNWthSdl0w_-QXsUlgpqyFG4Gswaewo7pSHjf2jBU07NyPEk3eyQ9foVrznwGSO3LHdvGyqyGQ-z_X2meVuGlONc1udQuz4mWaeiMNLea_7-EolzegKGKH-jakAFgmX4sqjPkVoB2SiCm3lytFyYe6kj1rb-WSrsOxM184ZI6o4k9KCoJW5croBK12WiGz7csyWn3CxItkZM7adHMsw/file\n",
            "Reusing existing connection to uc0798418d55059d281dff55852a.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9251149 (8.8M) [application/octet-stream]\n",
            "Saving to: ‘Task01_BrainTumour_2D.tar.gz’\n",
            "\n",
            "Task01_BrainTumour_ 100%[===================>]   8.82M  24.1MB/s    in 0.4s    \n",
            "\n",
            "2026-02-08 20:32:49 (24.1 MB/s) - ‘Task01_BrainTumour_2D.tar.gz’ saved [9251149/9251149]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-455641098.py:8: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "  datafile.extractall()\n"
          ]
        }
      ],
      "source": [
        "# Download the dataset\n",
        "# If you use Ubuntu, wget would natively work.\n",
        "# If you use Mac or Windows, which does not have the wget command, you can copy the URL to the web browser and download the file.\n",
        "!wget https://www.dropbox.com/s/zmytk2yu284af6t/Task01_BrainTumour_2D.tar.gz\n",
        "\n",
        "# Unzip the '.tar.gz' file to the current directory\n",
        "datafile = tarfile.open('Task01_BrainTumour_2D.tar.gz')\n",
        "datafile.extractall()\n",
        "datafile.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu_BTL0x6o5a"
      },
      "source": [
        "## Visualise a random set of 4 training images along with their label maps.\n",
        "\n",
        "Suggested colour map for brain MR image:\n",
        "```\n",
        "cmap = 'gray'\n",
        "```\n",
        "\n",
        "Suggested colour map for segmentation map:\n",
        "```\n",
        "cmap = colors.ListedColormap(['black', 'green', 'blue', 'red'])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3fgubCRC6m4k"
      },
      "outputs": [],
      "source": [
        "### Insert your code ###\n",
        "...\n",
        "### End of your code ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xWGT3KaML-D"
      },
      "source": [
        "## Q2. Implement a dataset class.\n",
        "\n",
        "It can read the imaging dataset and get items, pairs of images and label maps, to be used as training batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6p6wFZ3na5z9"
      },
      "outputs": [],
      "source": [
        "def normalise_intensity(image, thres_roi=1.0):\n",
        "    \"\"\" Normalise the image intensity by the mean and standard deviation \"\"\"\n",
        "    # ROI defines the image foreground\n",
        "    val_l = np.percentile(image, thres_roi)\n",
        "    roi = (image >= val_l)\n",
        "    mu, sigma = np.mean(image[roi]), np.std(image[roi])\n",
        "    eps = 1e-6\n",
        "    image2 = (image - mu) / (sigma + eps)\n",
        "    return image2\n",
        "\n",
        "\n",
        "class BrainImageSet(Dataset):\n",
        "    \"\"\" Brain image set \"\"\"\n",
        "    def __init__(self, image_path, label_path='', deploy=False):\n",
        "        self.image_path = image_path\n",
        "        self.deploy = deploy\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        image_names = sorted(os.listdir(image_path))\n",
        "        for image_name in image_names:\n",
        "            # Read the image\n",
        "            image = imageio.v2.imread(os.path.join(image_path, image_name))\n",
        "            self.images += [image]\n",
        "\n",
        "            # Read the label map\n",
        "            if not self.deploy:\n",
        "                label_name = os.path.join(label_path, image_name)\n",
        "                label = imageio.v2.imread(label_name)\n",
        "                self.labels += [label]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get an image and perform intensity normalisation\n",
        "        # Dimension: XY\n",
        "        image = normalise_intensity(self.images[idx])\n",
        "\n",
        "        # Get its label map\n",
        "        # Dimension: XY\n",
        "        label = self.labels[idx]\n",
        "        return image, label\n",
        "\n",
        "    def get_random_batch(self, batch_size):\n",
        "        # Get a batch of paired images and label maps\n",
        "        # Dimension of images: NCXY\n",
        "        # Dimension of labels: NXY\n",
        "        images, labels = [], []\n",
        "\n",
        "        ### Insert your code ###\n",
        "        ...\n",
        "        ### End of your code ###\n",
        "        return images, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa4ZpawDNmwu"
      },
      "source": [
        "## Q3. Build a U-net architecture.\n",
        "\n",
        "Implement a U-net architecture for image segmentation. If you are not familiar with U-net, you can read this paper:\n",
        "\n",
        "[1] Olaf Ronneberger et al. [U-Net: Convolutional networks for biomedical image segmentation](https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28). MICCAI, 2015.\n",
        "\n",
        "For the first convolutional layer, you can start with 16 filters. We have implemented the encoder path. Please complete the decoder path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IMPmBZVGb1aI"
      },
      "outputs": [],
      "source": [
        "\"\"\" U-net \"\"\"\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, input_channel=1, output_channel=1, num_filter=16):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        # BatchNorm: by default during training this layer keeps running estimates\n",
        "        # of its computed mean and variance, which are then used for normalization\n",
        "        # during evaluation.\n",
        "\n",
        "        # Encoder path\n",
        "        n = num_filter  # 16\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(input_channel, n, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        n *= 2  # 32\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(n),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        n *= 2  # 64\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(n),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        n *= 2  # 128\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(n),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Decoder path\n",
        "        ### Insert your code ###\n",
        "        ...\n",
        "        ### End of your code ###\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Use the convolutional operators defined above to build the U-net\n",
        "        # The encoder part is already done for you.\n",
        "        # You need to complete the decoder part.\n",
        "        # Encoder\n",
        "        x = self.conv1(x)\n",
        "        conv1_skip = x\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        conv2_skip = x\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        conv3_skip = x\n",
        "\n",
        "        x = self.conv4(x)\n",
        "\n",
        "        # Decoder\n",
        "        ### Insert your code ###\n",
        "        ...\n",
        "        ### End of your code ###\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcNWZS08d47P"
      },
      "source": [
        "## Q4. Train the segmentation model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xaGGkKQndIaR",
        "outputId": "cfc2f186-66b0-48ac-e25b-b9667d7460b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "expected np.ndarray (got list)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3467433545.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Get a batch of images and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_random_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got list)"
          ]
        }
      ],
      "source": [
        "# CUDA device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device: {0}'.format(device))\n",
        "\n",
        "# Build the model\n",
        "num_class = 4\n",
        "model = UNet(input_channel=1, output_channel=num_class, num_filter=16)\n",
        "model = model.to(device)\n",
        "params = list(model.parameters())\n",
        "\n",
        "model_dir = 'saved_models'\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(params, lr=1e-3)\n",
        "\n",
        "# Segmentation loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Datasets\n",
        "train_set = BrainImageSet('Task01_BrainTumour_2D/training_images', 'Task01_BrainTumour_2D/training_labels')\n",
        "test_set = BrainImageSet('Task01_BrainTumour_2D/test_images', 'Task01_BrainTumour_2D/test_labels')\n",
        "\n",
        "# Train the model\n",
        "# Note: when you debug the model, you may reduce the number of iterations or batch size to save time.\n",
        "num_iter = 10000\n",
        "train_batch_size = 16\n",
        "eval_batch_size = 16\n",
        "start = time.time()\n",
        "for it in range(1, 1 + num_iter):\n",
        "    # Set the modules in training mode, which will have effects on certain modules, e.g. dropout or batchnorm.\n",
        "    start_iter = time.time()\n",
        "    model.train()\n",
        "\n",
        "    # Get a batch of images and labels\n",
        "    images, labels = train_set.get_random_batch(train_batch_size)\n",
        "    images, labels = torch.from_numpy(images), torch.from_numpy(labels)\n",
        "    images, labels = images.to(device, dtype=torch.float32), labels.to(device, dtype=torch.long)\n",
        "    logits = model(images)\n",
        "\n",
        "    # Perform optimisation and print out the training loss\n",
        "    ### Insert your code ###\n",
        "    ...\n",
        "    ### End of your code ###\n",
        "\n",
        "    # Evaluate\n",
        "    if it % 1000 == 0:\n",
        "        model.eval()\n",
        "        # Disabling gradient calculation during reference to reduce memory consumption\n",
        "        with torch.no_grad():\n",
        "            # Evaluate on a batch of test images and print out the test loss\n",
        "            ### Insert your code ###\n",
        "            ...\n",
        "            ### End of your code ###\n",
        "\n",
        "    # Save the model\n",
        "    if it % 5000 == 0:\n",
        "        torch.save(model.state_dict(), os.path.join(model_dir, 'model_{0}.pt'.format(it)))\n",
        "print('Training took {:.3f}s in total.'.format(time.time() - start))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_bW-UjpU9UYe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89yjxjGyb6yT"
      },
      "source": [
        "## Q5. Deploy the trained model to a random set of 4 test images and visualise the automated segmentation.\n",
        "\n",
        "You can show the images as a 4 x 3 panel. Each row shows one example, with the 3 columns being the test image, automated segmentation and ground truth segmentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZeLE0qZjd2j"
      },
      "outputs": [],
      "source": [
        "### Insert your code ###\n",
        "...\n",
        "### End of your code ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj3Qusin_s_r"
      },
      "source": [
        "## Q6. Discussion. Does your trained model work well? How would you improve this model so it can be deployed to the real clinic?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVwEtDKIdTRs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}